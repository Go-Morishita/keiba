{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonを用いた競馬予測\n",
    "\n",
    "## インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # 正規表現\n",
    "import time\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ収集\n",
    "- カレンダーのページから開催日一覧を取得（スクレイピング）\n",
    "    1. 2023年1月：https://race.netkeiba.com/top/calendar.html?year=2023&month=1\n",
    "- 開催ページからレースid一覧を取得\n",
    "    1. 2023年1月5日開催：https://race.netkeiba.com/top/race_list.html?kaisai_date=20230105\n",
    "- レース結果ページからレース結果テーブル一覧を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "\n",
    "url = \"https://db.netkeiba.com/race/202306050811/\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"}\n",
    "\n",
    "req = Request(url, headers=headers)\n",
    "html = urlopen(req).read()\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_html(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html(html)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html(html)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html(html)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開催日一覧を取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://race.netkeiba.com/top/calendar.html?year=2023&month=1\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"}\n",
    "\n",
    "req = Request(url, headers=headers)\n",
    "html = urlopen(req).read()\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = soup.find(\"table\", class_=\"Calendar_Table\").find(\"a\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # 正規表現\n",
    "\n",
    "re.findall(r\"kaisai_date=(\\d{8})\", a[\"href\"])[0] # \\d{8}：8桁の数字（\\dは数字）()を付けるとその部分だけ取り出される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = soup.find(\"table\", class_=\"Calendar_Table\").findAll(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaisai_date_list = []\n",
    "for a in a_list:\n",
    "    kaisai_date = re.findall(r\"kaisai_date=(\\d{8})\", a[\"href\"])[0]\n",
    "    kaisai_date_list.append(kaisai_date)\n",
    "\n",
    "kaisai_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def scrape_kaisai_date(from_, to_):\n",
    "    \n",
    "    kaisai_date_list = []\n",
    "    \n",
    "    for date in tqdm(pd.date_range(from_, to_, freq=\"MS\")):\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        url = f\"https://race.netkeiba.com/top/calendar.html?year={year}&month={month}\"\n",
    "        \n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"}\n",
    "        req = Request(url, headers=headers)\n",
    "        html = urlopen(req).read()\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        a_list = soup.find(\"table\", class_=\"Calendar_Table\").find_all(\"a\")\n",
    "        \n",
    "        for a in a_list:\n",
    "            kaisai_date = re.findall(r\"kaisai_date=(\\d{8})\", a[\"href\"])[0]\n",
    "            kaisai_date_list.append(kaisai_date)\n",
    "        \n",
    "    return kaisai_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_kaisai_date(\"2023-01\", \"2023-12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開催ページからrace_idを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://race.netkeiba.com/top/race_list.html?kaisai_date=20230105\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"}\n",
    "req = Request(url, headers=headers)\n",
    "html = urlopen(req).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find(\"div\", class_=\"RaceList_Box\") # 動的jsで構成されている場合はBeautifulSoupでは要素を取得できない."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得できないので、ChromeDriverを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "driver_path = ChromeDriverManager().install()\n",
    "driver_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=Service(driver_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "li_list = driver.find_elements(By.CLASS_NAME, \"RaceList_DataItem\")\n",
    "li_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = li_list[0]\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = li.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "re.findall(r\"race_id=(\\d{12})\", href)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_list = []\n",
    "\n",
    "for li in li_list:\n",
    "    href = li.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "    race_id = re.findall(r\"race_id=(\\d{12})\", href)[0]\n",
    "    race_id_list.append(race_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(race_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaisai_date_list = scraping.scrape_kaisai_date(from_=\"2023-01\", to_=\"2023-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm.notebook import tqdm\n",
    "import traceback\n",
    "\n",
    "def scrape_race_id_list(kaisai_date_list: list[str]):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\") # 処理軽量化のためにバックグラウンドで実行\n",
    "    driver_path = ChromeDriverManager().install()\n",
    "    race_id_list = []\n",
    "    \n",
    "    # for文終了時にwith構文自動的にdriverがquitする.\n",
    "    with webdriver.Chrome(service=Service(driver_path),options=options) as driver:\n",
    "        for kaisai_date in tqdm(kaisai_date_list):\n",
    "            url = f\"https://race.netkeiba.com/top/race_list.html?kaisai_date={kaisai_date}\"\n",
    "            try:\n",
    "                driver.get(url)\n",
    "                time.sleep(1)\n",
    "                li_list = driver.find_elements(By.CLASS_NAME, \"RaceList_DataItem\")\n",
    "                for li in li_list:\n",
    "                    href = li.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                    race_id = re.findall(r\"race_id=(\\d{12})\", href)[0]\n",
    "                    race_id_list.append(race_id)\n",
    "            except:\n",
    "                print(f\"stopped at {url}\")\n",
    "                print(traceback.format_exc()) # エラー把握\n",
    "                break\n",
    "    return race_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_list = scrape_race_id_list(kaisai_date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スクリプトのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_list = scraping.scrape_race_id_list(kaisai_date_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebookにおけるモジュールのリロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_id_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
